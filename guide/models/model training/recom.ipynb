{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('crop_db.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N   P   K  temperature   humidity        ph    rainfall label\n",
      "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
      "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
      "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
      "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
      "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice\n"
     ]
    }
   ],
   "source": [
    "# View the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2200 entries, 0 to 2199\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   N            2200 non-null   int64  \n",
      " 1   P            2200 non-null   int64  \n",
      " 2   K            2200 non-null   int64  \n",
      " 3   temperature  2200 non-null   float64\n",
      " 4   humidity     2200 non-null   float64\n",
      " 5   ph           2200 non-null   float64\n",
      " 6   rainfall     2200 non-null   float64\n",
      " 7   label        2200 non-null   object \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 137.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of the dataset (types, null values, etc.)\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N              0\n",
      "P              0\n",
      "K              0\n",
      "temperature    0\n",
      "humidity       0\n",
      "ph             0\n",
      "rainfall       0\n",
      "label          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for any missing values\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 N            P            K  temperature     humidity  \\\n",
      "count  2200.000000  2200.000000  2200.000000  2200.000000  2200.000000   \n",
      "mean     50.551818    53.362727    48.149091    25.616244    71.481779   \n",
      "std      36.917334    32.985883    50.647931     5.063749    22.263812   \n",
      "min       0.000000     5.000000     5.000000     8.825675    14.258040   \n",
      "25%      21.000000    28.000000    20.000000    22.769375    60.261953   \n",
      "50%      37.000000    51.000000    32.000000    25.598693    80.473146   \n",
      "75%      84.250000    68.000000    49.000000    28.561654    89.948771   \n",
      "max     140.000000   145.000000   205.000000    43.675493    99.981876   \n",
      "\n",
      "                ph     rainfall  \n",
      "count  2200.000000  2200.000000  \n",
      "mean      6.469480   103.463655  \n",
      "std       0.773938    54.958389  \n",
      "min       3.504752    20.211267  \n",
      "25%       5.971693    64.551686  \n",
      "50%       6.425045    94.867624  \n",
      "75%       6.923643   124.267508  \n",
      "max       9.935091   298.560117  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get basic statistics of the dataset\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "rice           100\n",
      "maize          100\n",
      "chickpea       100\n",
      "kidneybeans    100\n",
      "pigeonpeas     100\n",
      "mothbeans      100\n",
      "mungbean       100\n",
      "blackgram      100\n",
      "lentil         100\n",
      "pomegranate    100\n",
      "banana         100\n",
      "mango          100\n",
      "grapes         100\n",
      "watermelon     100\n",
      "muskmelon      100\n",
      "apple          100\n",
      "orange         100\n",
      "papaya         100\n",
      "coconut        100\n",
      "cotton         100\n",
      "jute           100\n",
      "coffee         100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of the 'label' (crop names)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical target to numerical (Label Encoding)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.9773\n",
      "Gradient Boosting Confusion Matrix:\n",
      " [[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 26  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 21  0  0  0  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0 23  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 14  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  0 15  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Try Gradient Boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=3)\n",
    "gbc.fit(X_train_scaled, y_train)\n",
    "y_pred_gbc = gbc.predict(X_test_scaled)\n",
    "print(f\"Gradient Boosting Accuracy: {accuracy_score(y_test, y_pred_gbc):.4f}\")\n",
    "print(\"Gradient Boosting Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_gbc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No crop found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ravin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set a confidence threshold (e.g., 0.7 for 70% confidence)\n",
    "confidence_threshold = 0.7\n",
    "\n",
    "# Sample input for testing\n",
    "test_input = np.array([[10, 3, 0, 25, 90, 6, 00]])\n",
    "\n",
    "# Scaling the test input using the same scaler\n",
    "test_input_scaled = scaler.transform(test_input)\n",
    "\n",
    "# Predicting the probabilities for each class using Gradient Boosting Classifier\n",
    "predicted_probs = gbc.predict_proba(test_input_scaled)\n",
    "\n",
    "# Get the class with the highest probability and the corresponding probability value\n",
    "predicted_crop_index = np.argmax(predicted_probs, axis=1)\n",
    "max_prob = np.max(predicted_probs)\n",
    "\n",
    "# Check if the highest probability is above the confidence threshold\n",
    "if max_prob >= confidence_threshold:\n",
    "    # Convert numerical prediction back to the original crop label\n",
    "    predicted_crop = le.inverse_transform(predicted_crop_index)\n",
    "    print(f\"The recommended crop for the given input is: {predicted_crop[0]} with confidence {max_prob:.2f}\")\n",
    "else:\n",
    "    # If the confidence is too low, output \"No crop found\"\n",
    "    print(\"No crop found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained Random Forest model\n",
    "pickle.dump(rf, open('RFmodel.pkl', 'wb'))\n",
    "\n",
    "# Save the trained Gradient Boosting model\n",
    "pickle.dump(gbc, open('GBmodel.pkl', 'wb'))\n",
    "\n",
    "# Save the scaler (StandardScaler, MinMaxScaler, etc.)\n",
    "pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
    "\n",
    "# Save the LabelEncoder\n",
    "pickle.dump(le, open('label_encoder.pkl', 'wb'))\n",
    "\n",
    "print(\"Models and scaler saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  apple\n",
      "Max:  watermelon\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('crop_db.csv')\n",
    "#temperature,humidity,ph,rainfall,label\n",
    "\n",
    "min_value = df['label'].min()\n",
    "max_value = df['label'].max()\n",
    "\n",
    "print('Min: ', min_value)\n",
    "print('Max: ', max_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
